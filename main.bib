
@article{horstmann_robots_2018,
	title = {Do a robot’s social skills and its objection discourage interactants from switching the robot off?},
	volume = {13},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201581},
	doi = {10.1371/journal.pone.0201581},
	abstract = {Building on the notion that people respond to media as if they were real, switching off a robot which exhibits lifelike behavior implies an interesting situation. In an experimental lab study with a 2x2 between-subjects-design (N = 85), people were given the choice to switch off a robot with which they had just interacted. The style of the interaction was either social (mimicking human behavior) or functional (displaying machinelike behavior). Additionally, the robot either voiced an objection against being switched off or it remained silent. Results show that participants rather let the robot stay switched on when the robot objected. After the functional interaction, people evaluated the robot as less likeable, which in turn led to a reduced stress experience after the switching off situation. Furthermore, individuals hesitated longest when they had experienced a functional interaction in combination with an objecting robot. This unexpected result might be due to the fact that the impression people had formed based on the task-focused behavior of the robot conflicted with the emotional nature of the objection.},
	language = {en},
	number = {7},
	urldate = {2023-04-20},
	journal = {PLOS ONE},
	author = {Horstmann, Aike C. and Bock, Nikolai and Linhuber, Eva and Szczuka, Jessica M. and Straßmann, Carolin and Krämer, Nicole C.},
	month = jul,
	year = {2018},
	note = {Publisher: Public Library of Science},
	keywords = {Robots, Emotions, Experimental psychology, Fear, Instructors, Personality, Psychological attitudes, Robotic behavior},
	pages = {e0201581},
	file = {Full Text PDF:/Users/boonak/Zotero/storage/JK45TFBV/Horstmann et al. - 2018 - Do a robot’s social skills and its objection disco.pdf:application/pdf},
}

@inproceedings{bartneck_daisy_2007,
	address = {New York, NY, USA},
	series = {{HRI} '07},
	title = {"{Daisy}, {Daisy}, give me your answer do!": switching off a robot},
	isbn = {978-1-59593-617-2},
	shorttitle = {"{Daisy}, {Daisy}, give me your answer do!"},
	url = {https://dl.acm.org/doi/10.1145/1228716.1228746},
	doi = {10.1145/1228716.1228746},
	abstract = {Robots can exhibit life like behavior, but are according to traditional definitions not alive. Current robot users are confronted with an ambiguous entity and it is important to understand the users perception of these robots. This study analyses if a robot's intelligence and its agreeableness influence its perceived animacy. The robot's animacy was measured, amongst other measurements, by the users' hesitation to switch it off. The results show that participants hesitated three times as long to switch off an agreeable and intelligent robot as compared to a non agreeable and unintelligent robot. The robots' intelligence had a significant influence on its perceived animacy. Our results suggest that interactive robots should be intelligent and exhibit an agreeable attitude to maximize its perceived animacy.},
	urldate = {2023-04-20},
	booktitle = {Proceedings of the {ACM}/{IEEE} international conference on {Human}-robot interaction},
	publisher = {Association for Computing Machinery},
	author = {Bartneck, Christoph and van der Hoek, Michel and Mubin, Omar and Al Mahmud, Abdullah},
	month = mar,
	year = {2007},
	keywords = {animacy, human, intelligence, interaction, robot, switching off},
	pages = {217--222},
	file = {Full Text PDF:/Users/boonak/Zotero/storage/CQP87LGP/Bartneck et al. - 2007 - Daisy, Daisy, give me your answer do! switching.pdf:application/pdf},
}

@book{reeves_media_1996,
	address = {New York, NY, US},
	series = {The media equation:  {How} people treat computers, television, and new media like real people and places},
	title = {The media equation:  {How} people treat computers, television, and new media like real people and places},
	isbn = {978-1-57586-052-7},
	shorttitle = {The media equation},
	abstract = {According to popular wisdom, humans never relate to a computer or a TV program in the same way they relate to another human being. Or do they? Byron Reeves and Clifford Nass demonstrate . . . in "The Media Equation" that interactions with computers, TV, and new communication technologies are identical to real social relationships and to the navigation of real physical spaces.  [The] authors . . . present the results of numerous psychological studies that led them to the conclusion that people treat computers, TV and new media as real people and places. Their studies show that people are polite to computers; that they treat computers with female voices differently than male-voiced computers; that large faces on a screen can invade a person's body space; and that motion on a screen affects physical responses in the same way that real-life motion does. One of their startling conclusions is that the human brain has not evolved quickly enough to assimilate 20th-century technology. The authors detail how this knowledge can help us better design and evaluate media technologies, including computer and Internet software, TV entertainment, news, and advertising, and multi-media.  [This book is intended for] general readers with an interest in . . . research at the intersection of psychology, communication and computer technology. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Cambridge University Press},
	author = {Reeves, Byron and Nass, Clifford Ivar},
	year = {1996},
	note = {Pages: xiv, 305},
	keywords = {Emotions, Communication Systems, Computers, Human Computer Interaction, Personality Traits, Social Interaction, Technology, Television},
	file = {Snapshot:/Users/boonak/Zotero/storage/6XEQBR7W/1996-98923-000.html:text/html},
}

@article{leite_influence_2013,
	title = {The influence of empathy in human–robot relations},
	volume = {71},
	issn = {1071-5819},
	url = {https://www.sciencedirect.com/science/article/pii/S1071581912001681},
	doi = {10.1016/j.ijhcs.2012.09.005},
	abstract = {The idea of robotic companions capable of establishing meaningful relationships with humans remains far from being accomplished. To achieve this, robots must interact with people in natural ways, employing social mechanisms that people use while interacting with each other. One such mechanism is empathy, often seen as the basis of social cooperation and prosocial behaviour. We argue that artificial companions capable of behaving in an empathic manner, which involves the capacity to recognise another's affect and respond appropriately, are more successful at establishing and maintaining a positive relationship with users. This paper presents a study where an autonomous robot with empathic capabilities acts as a social companion to two players in a chess game. The robot reacts to the moves played on the chessboard by displaying several facial expressions and verbal utterances, showing empathic behaviours towards one player and behaving neutrally towards the other. Quantitative and qualitative results of 31 participants indicate that users towards whom the robot behaved empathically perceived the robot as friendlier, which supports our hypothesis that empathy plays a key role in human–robot interaction.},
	language = {en},
	number = {3},
	urldate = {2023-04-20},
	journal = {International Journal of Human-Computer Studies},
	author = {Leite, Iolanda and Pereira, André and Mascarenhas, Samuel and Martinho, Carlos and Prada, Rui and Paiva, Ana},
	month = mar,
	year = {2013},
	keywords = {Affective interactions, Artificial companions, Empathy, Friendship, Social robots},
	pages = {250--260},
	file = {ScienceDirect Full Text PDF:/Users/boonak/Zotero/storage/XAF92TTM/Leite et al. - 2013 - The influence of empathy in human–robot relations.pdf:application/pdf;ScienceDirect Snapshot:/Users/boonak/Zotero/storage/FXZ3KETD/S1071581912001681.html:text/html},
}

@article{kahn_jr_robovie_2012,
	title = {“{Robovie}, you'll have to go into the closet now”: {Children}'s social and moral relationships with a humanoid robot},
	volume = {48},
	issn = {1939-0599},
	shorttitle = {“{Robovie}, you'll have to go into the closet now”},
	doi = {10.1037/a0027033},
	abstract = {Children will increasingly come of age with personified robots and potentially form social and even moral relationships with them. What will such relationships look like? To address this question, 90 children (9-, 12-, and 15-year-olds) initially interacted with a humanoid robot, Robovie, in 15-min sessions. Each session ended when an experimenter interrupted Robovie's turn at a game and, against Robovie's stated objections, put Robovie into a closet. Each child was then engaged in a 50-min structural–developmental interview. Results showed that during the interaction sessions, all of the children engaged in physical and verbal social behaviors with Robovie. The interview data showed that the majority of children believed that Robovie had mental states (e.g., was intelligent and had feelings) and was a social being (e.g., could be a friend, offer comfort, and be trusted with secrets). In terms of Robovie's moral standing, children believed that Robovie deserved fair treatment and should not be harmed psychologically but did not believe that Robovie was entitled to its own liberty (Robovie could be bought and sold) or civil rights (in terms of voting rights and deserving compensation for work performed). Developmentally, while more than half the 15-year-olds conceptualized Robovie as a mental, social, and partly moral other, they did so to a lesser degree than the 9- and 12-year-olds. Discussion focuses on how (a) children's social and moral relationships with future personified robots may well be substantial and meaningful and (b) personified robots of the future may emerge as a unique ontological category. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
	journal = {Developmental Psychology},
	author = {Kahn Jr., Peter H. and Kanda, Takayuki and Ishiguro, Hiroshi and Freier, Nathan G. and Severson, Rachel L. and Gill, Brian T. and Ruckert, Jolina H. and Shen, Solace},
	year = {2012},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Robotics, Human Computer Interaction, Autonomy, Child Attitudes, Human Robot Interaction, Independence (Personality), Mental Models},
	pages = {303--314},
	file = {Snapshot:/Users/boonak/Zotero/storage/T4F8MHBL/2012-04837-001.html:text/html},
}

@article{olaronke_state_2017,
	title = {State {Of} {The} {Art}: {A} {Study} of {Human}-{Robot} {Interaction} in {Healthcare}},
	volume = {9},
	issn = {20749023, 20749031},
	shorttitle = {State {Of} {The} {Art}},
	url = {http://www.mecs-press.org/ijieeb/ijieeb-v9-n3/v9n3-6.html},
	doi = {10.5815/ijieeb.2017.03.06},
	abstract = {In general, the applications of robots have shifted rapidly from industrial uses to social uses. This provides robots with the ability to naturally interact with human beings and socially fit into the human environment. The deployment of social robots in the healthcare system is becoming extensive as a result of the shortage of healthcare professionals, rising costs of healthcare and the exponential growth in the number of vulnerable populations such as the sick, the aged and children with developmental disabilities. Consequently, social robots are used in healthcare for providing health education and entertainment for patients in the hospital and for providing aids for the sick and aged. They are also used for dispensing drugs and providing rehabilitation as well as emotional and aging care. Hence, social robots improve the efficiency and quality of healthcare services. The interaction between social robots and human beings is known as human-robot interaction. Human-robot interaction in healthcare is faced with numerous challenges such as the fear of displacement of caregivers by robots, safety, usefulness, acceptability as well as appropriateness. These challenges ultimately lead to a low rate of acceptance of the robotic technology. Consequently, this paper extensively appraises humanrobot interaction in healthcare, their applications and challenges. Design, ethical and usability issues such as privacy, trust, safety, users‘ attitude, culture, robot morphology as well as emotions and deception arising from the interaction between humans and robots in healthcare are also reviewed in this paper.},
	language = {en},
	number = {3},
	urldate = {2023-04-21},
	journal = {International Journal of Information Engineering and Electronic Business},
	author = {Olaronke, Iroju and Oluwaseun, Ojerinde and Rhoda, Ikono},
	month = may,
	year = {2017},
	pages = {43--55},
	file = {Department of Computer Science, Adeyemi College of Education, Ondo, Nigeria et al. - 2017 - State Of The Art A Study of Human-Robot Interacti.pdf:/Users/boonak/Zotero/storage/Y3GR6DNP/Department of Computer Science, Adeyemi College of Education, Ondo, Nigeria et al. - 2017 - State Of The Art A Study of Human-Robot Interacti.pdf:application/pdf},
}

@incollection{mende_use_2019,
	address = {Cham},
	title = {The {Use} of {Social} {Robots} and the {Uncanny} {Valley} {Phenomenon}},
	isbn = {978-3-030-19734-6},
	url = {https://doi.org/10.1007/978-3-030-19734-6\_3},
	abstract = {Social robots are increasingly used in different areas of society such as public health, elderly care, education, and commerce. They have also been successfully employed in autism spectrum disorders therapy with children. Humans strive to find in them not only assistants but also friends. Although forms and functionalities of such robots vary, there is a strong tendency to anthropomorphize artificial agents, making them look and behave as human as possible and imputing human attributes to them. The more human a robot looks, the more appealing it will be considered by humans. However, this linear link between likeness and liking only holds to the point where a feeling of strangeness and eeriness emerges. We discuss possible explanations of this so-called uncanny valley phenomenon that emerges in human–robot interaction. We also touch upon important ethical questions surrounding human–robot interaction in different social settings, such as elderly care or autism spectrum disorders therapy.},
	language = {en},
	urldate = {2023-04-22},
	booktitle = {{AI} {Love} {You}: {Developments} in {Human}-{Robot} {Intimate} {Relationships}},
	publisher = {Springer International Publishing},
	author = {Mende, Melinda A. and Fischer, Martin H. and Kühne, Katharina},
	editor = {Zhou, Yuefang and Fischer, Martin H.},
	year = {2019},
	doi = {10.1007/978-3-030-19734-6_3},
	keywords = {Anthropomorphism, Autism, Humanoid robots, Pet robots, Social robots, Uncanny valley},
	pages = {41--73},
}

@inproceedings{duffy_what_1999,
	title = {What is a social robot?},
	url = {http://hdl.handle.net/10197/4412},
	abstract = {This paper discusses the concept of a social robot. Developing from recent work on physical embodiment, the necessity for a socially embodied robot is presented. Current work via the Social Robot Architecture seeks to develop and demonstrate these concepts.},
	language = {en},
	urldate = {2023-04-22},
	booktitle = {10th {Irish} {Conference} on {Artificial} {Intelligence} \& {Cognitive} {Science}, {University} {College} {Cork}, {Ireland}, 1-3 {September}, 1999},
	author = {Duffy, Brian R. and Rooney, Colm and O'Hare, G. M. P. (Greg M. P. ) and O'Donoghue, Ruadhan},
	month = sep,
	year = {1999},
	file = {Full Text PDF:/Users/boonak/Zotero/storage/QBQC62Z3/Duffy et al. - 1999 - What is a social robot.pdf:application/pdf},
}
